# %% [markdown]
# # Lift test
# In this example, we will show how you can leverage lift tests executed in the past to improve the detection of the effect of an intervention.
# This example is inspired by the one in [PyMC-Marketing documentation](https://www.pymc-marketing.io/en/stable/notebooks/mmm/mmm_lift_test.html).
#
# ## Get data from simulated dataset
# In this exercise, we will load  a synthetic dataset
# composed of a target timeseries (sales, for example) and
# two exogenous variables (investment1 and investment2).
# The two variables are highly correlated.
#
# From this dataset, we also obtain the results of a lift test.
# %%
import numpyro
import matplotlib.pyplot as plt

numpyro.enable_x64()
numpyro.enable_validation()


from prophetverse.datasets._mmm.lifttest import get_dataset

y, X, lift_test, true_effect, model = get_dataset()


# %%

fig, ax = plt.subplots(figsize=(10, 15), nrows=3, sharex=True)
y.plot.line(ax=ax[0])
ax[0].set_title("Sales")
X.plot.line(alpha=0.9, ax=ax[1])
ax[1].set_title("Exogenous variables")
true_effect.plot.line(ax=ax[2])
ax[2].set_title("True effect of investment1 and investment2")
fig.show()

# %%

true_components = model.predict_component_samples(X=X, fh=X.index).loc[0]

fig, axs = plt.subplots(figsize=(10, 15), nrows=4)
ax = axs[0]
true_components["trend"].plot.line(ax=ax, label="True observed")

ax = axs[1]
true_components["yearly_seasonality"].plot.line(ax=ax, label="True observed")

ax = axs[2]
true_components["weekly_seasonality"].plot.line(ax=ax, label="True observed")

ax = axs[3]
true_components["investment1"].plot.line(ax=ax, label="True observed")
true_components["investment2"].plot.line(ax=ax, label="True observed")

fig.show()


# %% [markdown]
# The lift test dataframe looks like below, with the information
# of how a delta in the exogenous variable (investment1 and investment2)
# affects the target variable (sales). Note that the lift test
# is assigned to dates, since the effect of the intervention can
# vary with time.

# %%

lift_test1, lift_test2 = lift_test
lift_test1

# %% [markdown]
# ## Creating the model
# We create the model to estimate the effect of the exogenous variables.
# Since this is an exercise, we use the effects that are the ground truth.
# However, we will see that even with a correct specification, the correlated
# exogenous variables can lead to bad estimates.
# %%
import numpyro.distributions as dist

from prophetverse.effects import HillEffect, LinearEffect, LinearFourierSeasonality
from prophetverse.effects.trend import PiecewiseLinearTrend
from prophetverse.engine import MAPInferenceEngine, MCMCInferenceEngine
from prophetverse.engine.optimizer import LBFGSSolver, CosineScheduleAdamOptimizer
from prophetverse.sktime import Prophetverse
from prophetverse.utils.regex import exact, no_input_columns

base_model = Prophetverse(
    trend=PiecewiseLinearTrend(
        changepoint_interval=100,
        changepoint_prior_scale=0.001,
        changepoint_range=-100,
    ),
    exogenous_effects=[
        (
            "yearly_seasonality",
            LinearFourierSeasonality(
                freq="D",
                sp_list=[365.25],
                fourier_terms_list=[4],
                prior_scale=0.1,
                effect_mode="multiplicative",
            ),
            no_input_columns,
        ),
        (
            "monthly_seasonality",
            LinearFourierSeasonality(
                freq="D",
                sp_list=[28],
                fourier_terms_list=[3],
                prior_scale=0.01,
                effect_mode="multiplicative",
            ),
            no_input_columns,
        ),
        (
            "weekly_seasonality",
            LinearFourierSeasonality(
                freq="D",
                sp_list=[7],
                fourier_terms_list=[3],
                prior_scale=0.1,
                effect_mode="multiplicative",
            ),
            no_input_columns,
        ),
        (
            "investment1",
            HillEffect(
                half_max_prior=dist.InverseGamma(3, 3),
                slope_prior=dist.InverseGamma(3, 3),
                max_effect_prior=dist.InverseGamma(3, 2),
                offset_slope=1,
                input_scale=1e5,
                effect_mode="additive",
            ),
            exact("investment1"),
        ),
        (
            "investment2",
            HillEffect(
                half_max_prior=dist.InverseGamma(3, 3),
                slope_prior=dist.InverseGamma(3, 3),
                max_effect_prior=dist.InverseGamma(3, 2),
                offset_slope=1,
                input_scale=1e5,
                effect_mode="additive",
            ),
            exact("investment2"),
        ),
    ],
    # inference_engine=MAPInferenceEngine(
    #    num_steps=10,
    #    optimizer=LBFGSSolver(memory_size=200, max_linesearch_steps=200),
    #    progress_bar=True,
    # ),
    inference_engine=MCMCInferenceEngine(
        num_samples=200, num_warmup=800, num_chains=1, dense_mass=True
    ),
)


if False:
    model = model.clone()
    model.set_params(
        investment1=HillEffect(
            half_max_prior=dist.HalfNormal(2),
            slope_prior=dist.HalfNormal(5),
            max_effect_prior=dist.HalfNormal(0.1),
            offset_slope=1,
            input_scale=1e5,
            effect_mode="additive",
        ),
        investment2=HillEffect(
            half_max_prior=dist.HalfNormal(2),
            slope_prior=dist.HalfNormal(2),
            max_effect_prior=dist.HalfNormal(0.1),
            offset_slope=1,
            input_scale=1e5,
            effect_mode="additive",
        ),
        inference_engine=MCMCInferenceEngine(
            num_samples=500,
            num_warmup=500,
            num_chains=1,
            dense_mass=True,
        ),
        # inference_engine=MAPInferenceEngine(
        #     num_steps=50_000,
        #     # optimizer=LBFGSSolver(
        #     #    memory_size=200, max_linesearch_steps=200
        #     # ),
        #     optimizer=CosineScheduleAdamOptimizer(decay_steps=50_000, init_value=1e-3),
        #     progress_bar=True,
        # ),
        trend=PiecewiseLinearTrend(
            changepoint_interval=100,
            changepoint_prior_scale=0.001,
            changepoint_range=-100,
        ),
        scale=None,
        likelihood="normal",
    )

numpyro.enable_x64()

base_model = model.clone()
base_model.set_params(
    investment1=HillEffect(
        half_max_prior=dist.HalfNormal(1),
        slope_prior=dist.InverseGamma(2, 1),
        max_effect_prior=dist.InverseGamma(2, 1),
        offset_slope=0,
        input_scale=1e6,
        effect_mode="additive",
    ),
    investment2=HillEffect(
        half_max_prior=dist.HalfNormal(1),
        slope_prior=dist.InverseGamma(2, 1),
        max_effect_prior=dist.InverseGamma(2, 1),
        offset_slope=0,
        input_scale=1e6,
        effect_mode="additive",
    ),
    # inference_engine=MCMCInferenceEngine(
    #     num_samples=500,
    #     num_warmup=500,
    #     num_chains=1,
    #     dense_mass=True,
    # ),
    inference_engine=MAPInferenceEngine(
        num_steps=50_000,
        optimizer=LBFGSSolver(memory_size=200, max_linesearch_steps=200),
        # optimizer=CosineScheduleAdamOptimizer(decay_steps=50_000, init_value=1e-3),
        progress_bar=True,
    ),
    trend=PiecewiseLinearTrend(
        changepoint_interval=100,
        changepoint_prior_scale=0.001,
        changepoint_range=-100,
    ),
    scale=None,
    likelihood="normal",
)
base_model.fit(y=y, X=X)
components = base_model.predict_components(fh=X.index, X=X)

# %%

fig, ax = plt.subplots(figsize=(10, 5))
y.plot.line(ax=ax, color="black", label="Sales")
components["mean"].to_frame("Forecast").plot.line(ax=ax)
fig.show()

# %%

fig, axs = plt.subplots(figsize=(10, 10), nrows=2, sharex=True)

ax = axs[0]

ax.scatter(X["investment1"], components["investment1"], label="Inferred effect")
ax.scatter(
    X["investment1"], true_effect["investment1"], label="True effect", color="black"
)
ax.set_title("Investment1")
ax.legend()

ax = axs[1]
ax.scatter(X["investment2"], components["investment2"])
ax.scatter(X["investment2"], true_effect["investment2"], color="black")
ax.set_title("Investment2")

fig.show()

# %% [markdown]

# ## Using lift test to improve the estimation
# We will use the lift test to improve the estimation of the effect of the exogenous variables.
# We wrap the original effects of `investment1` and `investment2` in a `LiftExperimentLikelihood` effect.
# This effect will use the lift test data to add a new likelihood term to the model.
#
# ### Creating the effects
# %%

from prophetverse.effects.lift_likelihood import LiftExperimentLikelihood

lift_experiment_effect1 = LiftExperimentLikelihood(
    effect=base_model.get_params()["investment1"],
    lift_test_results=lift_test1,
    prior_scale=0.05,
    likelihood_scale=1,
)

lift_experiment_effect2 = LiftExperimentLikelihood(
    effect=base_model.get_params()["investment2"],
    lift_test_results=lift_test2,
    prior_scale=0.05,
    likelihood_scale=1,
)

# %% [markdown]
# ### Fitting the new model

# %%
new_model = base_model.clone()
new_model.set_params(
    investment1=lift_experiment_effect1,
    investment2=lift_experiment_effect2,
    # inference_engine__num_warmup=800,
    # inference_engine__progress_bar=True,
    # inference_engine__num_steps=100_000,
    # inference_engine__optimizer=CosineScheduleAdamOptimizer(
    #    decay_steps=100_000, init_value=1e-2
    # ),
)
new_model.fit(y=y, X=X)


# %%
new_components = new_model.predict_components(fh=X.index, X=X)

# %%

fig, ax = plt.subplots(figsize=(10, 5))
components["obs"].plot.line(ax=ax)
y.plot.line(ax=ax, color="black")
new_components["obs"].plot.line(ax=ax)

# %%
fig, axs = plt.subplots(figsize=(10, 10), nrows=2, sharex=True)

ax = axs[0]

ax.scatter(
    X["investment1"],
    components["investment1"],
    label="Previous inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment1"],
    new_components["investment1"],
    label="New inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment1"], true_effect["investment1"], label="True effect", color="black"
)
ax.set_title("Investment1")
ax.legend()

ax = axs[1]
ax.scatter(
    X["investment2"],
    components["investment2"],
    label="Previous inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment2"],
    new_components["investment2"],
    label="New inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment2"], true_effect["investment2"], color="black", label="True effect"
)
ax.set_title("Investment2")
ax.legend()
fig.show()

# %%

fig, ax = plt.subplots(figsize=(10, 10), nrows=1, sharex=True)


ax.scatter(
    X["investment1"],
    components["investment1"],
    label="Previous inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment1"],
    new_components["investment1"],
    label="New inferred effect",
    alpha=0.5,
)
ax.scatter(
    X["investment1"], true_effect["investment1"], label="True effect", color="black"
)
ax.set_title("Investment1")


for i, row in lift_test1.sample(10, replace=False).iterrows():
    ax.plot(
        [row["x_start"], row["x_end"]],
        [row["y_start"], row["y_end"]],
        label="Lift test",
        color="red",
        alpha=0.5,
    )
    ax.scatter(
        row["x_start"],
        row["y_start"],
        label="Lift test",
        color="red",
        alpha=1,
    )

    ax.scatter(
        row["x_end"],
        row["y_end"],
        label="Lift test",
        color="red",
        alpha=1,
        marker="x",
    )

# %%
fig, ax = plt.subplots(figsize=(10, 5))

true_components["trend"].plot.line(ax=ax, label="True trend")
new_components["trend"].plot.line(ax=ax, label="New trend")
ax.set_title("Trend")

fig.show()

fig, ax = plt.subplots(figsize=(10, 5))
new_components["yearly_seasonality"].plot.line(ax=ax, label="New yearly seasonality")
true_components["yearly_seasonality"].plot.line(ax=ax, label="True yearly seasonality")
fig.show()

fig, ax = plt.subplots(figsize=(10, 5))
new_components["investment1"].plot.line(ax=ax, label="New yearly seasonality")
true_components["investment1"].plot.line(ax=ax, label="True yearly seasonality")
fig.show()

fig, ax = plt.subplots(figsize=(10, 5))
new_components["investment2"].plot.line(ax=ax, label="New yearly seasonality")
true_components["investment2"].plot.line(ax=ax, label="True yearly seasonality")
fig.show()

#
# ## Conclusion
#
# In this example, we showed how you can use lift tests to improve the estimation of the effect of exogenous variables.
# The highlights are the following:
#
# - We used a synthetic dataset with two exogenous variables that are highly correlated.
# - We showed that even with a correct specification of the model, the correlated exogenous variables can lead to bad estimates.
# - We then used the lift test to improve the estimation of the effect of the exogenous variables.
# - We wrapped the original effects in a `LiftExperimentLikelihood` effect that uses the lift test data to add a new likelihood term to the model.

# %%
