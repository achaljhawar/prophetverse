# %% [markdown]
# # Forecasting with Adstock and Saturation Effects
#
# This notebook demonstrates how to load a synthetic marketing mix dataset using `get_dataset()`
# from `prophetverse.datasets._mmm.lifttest`, and fit a Prophetverse model with
# **adstock** and **saturation** effects. We will:
#
# 1. Load the data with `get_dataset()`
# 2. Fit a Prophetverse model chaining `GeometricAdstockEffect` and `HillEffect`
# 3. Generate in-sample predictions and components
# 4. Perform backtesting via cross-validation
# 5. Visualize saturation curves
#
# ---
#
# %%
import numpyro
import pandas as pd
import matplotlib.pyplot as plt

plt.style.use("seaborn-v0_8-whitegrid")
numpyro.enable_x64()

from prophetverse.datasets._mmm.lifttest import get_dataset

# 1. Load synthetic data
y, X, lift_tests, true_components, _ = get_dataset()
# Quick inspection
print(f"Target (y) shape: {y.shape}")
print(f"Exogenous (X) shape: {X.shape}")
X.head()
# %% [markdown]
# ## 2. In-Sample Prediction
#
# We build a Prophetverse model with:
# - Piecewise linear trend
# - Yearly and weekly seasonality
# - Channel effects: Geometric Adstock + Hill Saturation
#
# %%

import matplotlib.pyplot as plt
import numpyro.distributions as dist
from prophetverse.effects import (
    PiecewiseLinearTrend,
    LinearFourierSeasonality,
    ChainedEffects,
    GeometricAdstockEffect,
    HillEffect,
)
from prophetverse.sktime import Prophetverse
from prophetverse.engine import MAPInferenceEngine
from prophetverse.engine.optimizer import LBFGSSolver

# Define seasonalities
yearly = (
    "yearly_seasonality",
    LinearFourierSeasonality(
        freq="D",
        sp_list=[365.25],
        fourier_terms_list=[5],
        prior_scale=0.1,
        effect_mode="multiplicative",
    ),
    None,
)
weekly = (
    "weekly_seasonality",
    LinearFourierSeasonality(
        freq="D",
        sp_list=[7],
        fourier_terms_list=[3],
        prior_scale=0.05,
        effect_mode="multiplicative",
    ),
    None,
)
# Adstock + saturation effect
hill = HillEffect(
    half_max_prior=dist.HalfNormal(1),
    slope_prior=dist.InverseGamma(2, 1),
    max_effect_prior=dist.HalfNormal(1),
    effect_mode="additive",
    input_scale=1e6,
)
chained_search = (
    "ad_spend_search",
    ChainedEffects(
        [
            ("adstock", GeometricAdstockEffect()),
            ("saturation", hill),
        ]
    ),
    "ad_spend_search",
)
chained_social = (
    "ad_spend_social_media",
    ChainedEffects(
        [
            ("adstock", GeometricAdstockEffect()),
            ("saturation", hill),
        ]
    ),
    "ad_spend_social_media",
)

# Build and fit model
model = Prophetverse(
    trend=PiecewiseLinearTrend(changepoint_interval=100),
    exogenous_effects=[yearly, weekly, chained_search, chained_social],
    inference_engine=MAPInferenceEngine(
        num_steps=5000, optimizer=LBFGSSolver(memory_size=200, max_linesearch_steps=200)
    ),
)

model.fit(y=y, X=X)
# In-sample prediction
y_pred = model.predict(X=X, fh=X.index)
# Plot observed vs predicted
plt.figure(figsize=(12, 4))
y.plot(label="Observed")
y_pred.plot(label="Predicted")
plt.legend()
plt.title("In-Sample Forecast: Observed vs Predicted")
plt.show()
# %% [markdown]
# ## 3. Component-Level Diagnostics
#
# Compare estimated components against true values for trend, seasonality, and channel effects.
#
# %%
y_pred_components = model.predict_components(X=X, fh=X.index)


fig, axes = plt.subplots(nrows=4, figsize=(12, 12))
# Trend
t_true = true_components["trend"]
t_est = y_pred_components["trend"]
t_true.plot(ax=axes[0], label="True Trend", color="black")
t_est.plot(ax=axes[0], label="Estimated Trend")
axes[0].legend()
# Yearly seasonality
y_true = true_components["yearly_seasonality"]
y_est = y_pred_components["yearly_seasonality"]
y_true.plot(ax=axes[1], label="True Yearly", color="black")
y_est.plot(ax=axes[1], label="Estimated Yearly")
axes[1].legend()
# Channel effects
for i, channel in enumerate(["ad_spend_search", "ad_spend_social_media"], start=2):
    true_components[channel].plot(ax=axes[i], label="True Effect", color="black")
    y_pred_components[channel].plot(ax=axes[i], label="Estimated Effect")
    axes[i].set_title(channel)
    axes[i].legend()
fig.tight_layout()
plt.show()
# %% [markdown]
# ## 4. Backtesting with Cross-Validation
#
# We perform rolling-window cross-validation to evaluate out-of-sample performance using MAPE.
#
# %%
from sktime.performance_metrics.forecasting import MeanAbsolutePercentageError
from sktime.split import ExpandingWindowSplitter
from sktime.forecasting.model_evaluation import evaluate

metric = MeanAbsolutePercentageError()
cv = ExpandingWindowSplitter(
    initial_window=365 * 3, step_length=180, fh=list(range(1, 180))
)
results = evaluate(
    forecaster=model,
    y=y,
    X=X,
    cv=cv,
    scoring=metric,
    error_score="raise",
    return_data=True,
)
print("Average OOS MAPE:", results["test_MeanAbsolutePercentageError"].mean())

# %%
import matplotlib.pyplot as plt

# Plot each fold
for idx, row in results.iterrows():

    plt.figure(figsize=(10, 4))
    data = pd.concat([row["y_train"].iloc[-100:], row["y_test"]])
    data.plot(label="Observed", color="black")
    row["y_pred"].plot(label="Prediction")
    plt.title(f"Fold {idx+1} â€“ MAPE: {row['test_MeanAbsolutePercentageError']:.2%}")
    plt.legend()
    plt.show()

    if idx > 3:
        break  # Limit to first 4 folds for brevity
# %% [markdown]
# ## 5. Saturation Curves
#
# Plot the marginal ROI (effect / baseline) vs spend for each channel.
#
# %%
baseline = y_pred_components["trend"] + y_pred_components["yearly_seasonality"]
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
for channel in ["ad_spend_search", "ad_spend_social_media"]:
    plt.scatter(X[channel], y_pred_components[channel], alpha=0.6, label=channel)
plt.xlabel("Daily Spend")
plt.ylabel("Incremental Effect")
plt.title("Saturation Curves")
plt.legend()
plt.show()

# %%
